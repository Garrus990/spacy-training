{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984c010c-80d0-4d00-b669-69b8419c3744",
   "metadata": {},
   "source": [
    "# Processing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b241262-7434-47a7-b7a1-cf9aa8bca4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "import pprint\n",
    "\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4cb669-9c89-4c19-99d2-f9018dc62b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f1d15f-ee46-4cc3-8c9d-5782e6ce861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9db41e-2b7e-4bd6-928f-6bcbb6890651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc98dc7-843a-438a-b6f8-d7d518a5cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7fedeb88edc0>),\n",
      " ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7fedeb88ee20>),\n",
      " ('parser',\n",
      "  <spacy.pipeline.dep_parser.DependencyParser object at 0x7fee2f745660>),\n",
      " ('attribute_ruler',\n",
      "  <spacy.pipeline.attributeruler.AttributeRuler object at 0x7fedeb460780>),\n",
      " ('lemmatizer',\n",
      "  <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7fedec4016c0>),\n",
      " ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7fee2f7459e0>)]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192d2d7-0108-469d-9ba3-c9e4ecd59d93",
   "metadata": {},
   "source": [
    "### Adding a custom component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91adc5d6-c945-4016-820a-c39c33745405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['custom_component', 'tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a custom component\n",
    "@Language.component(\"custom_component\")\n",
    "def custom_component_function(doc):\n",
    "    # Print the doc's length\n",
    "    print(\"Doc length:\", len(doc))\n",
    "    # Return the doc object\n",
    "    return doc\n",
    "\n",
    "# Add the component first in the pipeline\n",
    "nlp.add_pipe(\"custom_component\", first=True)\n",
    "\n",
    "# Print the pipeline component names\n",
    "print(\"Pipeline:\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6318dab1-cb29-4169-8794-39199362998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc length: 3\n"
     ]
    }
   ],
   "source": [
    "# process text with custom component\n",
    "doc = nlp(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056eb3a7-7674-4b25-be07-734095b138eb",
   "metadata": {},
   "source": [
    "### Setting custom attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "badc5d68-fbd9-4a21-8b36-3dd07a96f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd06d32-03d7-4310-a678-488ca88c10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import global classes\n",
    "from spacy.tokens import Doc, Token, Span\n",
    "\n",
    "# Set extensions on the Doc, Token and Span\n",
    "Doc.set_extension(\"title\", default=None)\n",
    "Token.set_extension(\"is_color\", default=False)\n",
    "Span.set_extension(\"has_color\", default=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90830e77-179b-4a58-9c76-5c0b29943154",
   "metadata": {},
   "source": [
    "**Extension attribute types**\n",
    "\n",
    "1. Attribute extensions\n",
    "2. Property extensions\n",
    "3. Method extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa161b39-60a5-439d-85ab-28d24b03ab30",
   "metadata": {},
   "source": [
    "#### Attribute extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec329e78-dae4-479a-8bd1-9f3d0cbb193f",
   "metadata": {},
   "source": [
    "Attribute extensions set a default value that can be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1300b36-f4bd-4b7e-afab-b2a3ec7a2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "\n",
    "# Set extension on the Token with default value\n",
    "Token.set_extension(\"is_color\", default=False, force=True)\n",
    "\n",
    "doc = nlp(\"The sky is blue.\")\n",
    "\n",
    "# Overwrite extension attribute value\n",
    "doc[3]._.is_color = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d736705e-9dc9-4c86-adde-61ce5513a1a7",
   "metadata": {},
   "source": [
    "#### Property extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c23d9d-ceaf-4395-be19-79858af32101",
   "metadata": {},
   "source": [
    "Property extensions work like properties in Python: they can define a getter function and an optional setter.\n",
    "\n",
    "The getter function is only called when you retrieve the attribute. This lets you compute the value dynamically, and even take other custom attributes into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "642abeca-bae4-4bf4-86e0-1e7d70b8cee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True - blue\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Token\n",
    "\n",
    "# Define getter function\n",
    "def get_is_color(token):\n",
    "    colors = [\"red\", \"yellow\", \"blue\"]\n",
    "    return token.text in colors\n",
    "\n",
    "# Set extension on the Token with getter\n",
    "Token.set_extension(\"is_color\", getter=get_is_color, force=True)\n",
    "\n",
    "doc = nlp(\"The sky is blue.\")\n",
    "print(doc[3]._.is_color, \"-\", doc[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fe163ac-76f1-4c7e-8e36-6c7e4716090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True - sky is blue\n",
      "False - The sky\n"
     ]
    }
   ],
   "source": [
    "### SPAN EXTENSION\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# Define getter function\n",
    "def get_has_color(span):\n",
    "    colors = [\"red\", \"yellow\", \"blue\"]\n",
    "    return any(token.text in colors for token in span)\n",
    "\n",
    "# Set extension on the Span with getter\n",
    "Span.set_extension(\"has_color\", getter=get_has_color, force=True)\n",
    "\n",
    "doc = nlp(\"The sky is blue.\")\n",
    "print(doc[1:4]._.has_color, \"-\", doc[1:4].text)\n",
    "print(doc[0:2]._.has_color, \"-\", doc[0:2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071ac64-77b5-4a3c-b9fe-2f2fab151c36",
   "metadata": {},
   "source": [
    "#### Method extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b99af6-65ab-4031-a01e-f908634857e7",
   "metadata": {},
   "source": [
    "Method extensions make the extension attribute a callable method.\n",
    "\n",
    "You can then pass one or more arguments to it, and compute attribute values dynamically â€“ for example, based on a certain argument or setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92bdc7dc-9feb-4c4f-b32c-b9bcb3c902b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True - blue\n",
      "False - cloud\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "# Define method with arguments\n",
    "def has_token(doc, token_text):\n",
    "    in_doc = token_text in [token.text for token in doc]\n",
    "    return in_doc\n",
    "\n",
    "# Set extension on the Doc with method\n",
    "Doc.set_extension(\"has_token\", method=has_token)\n",
    "\n",
    "doc = nlp(\"The sky is blue.\")\n",
    "print(doc._.has_token(\"blue\"), \"- blue\")\n",
    "print(doc._.has_token(\"cloud\"), \"- cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f282f-7be4-4960-a699-0b1e68433447",
   "metadata": {},
   "source": [
    "## Scaling and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab424e2-90f2-4eff-9f3f-580a9694323f",
   "metadata": {},
   "source": [
    "If you need to process a lot of texts and create a lot of `Doc` objects in a row, the `nlp.pipe` method can speed this up significantly.\n",
    "\n",
    "It processes the texts as a stream and yields `Doc` objects.\n",
    "\n",
    "It is much faster than just calling nlp on each text, because it batches up the texts.\n",
    "\n",
    "`nlp.pipe` is a generator that yields `Doc` objects, so in order to get a list of docs, remember to call the list method around it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795af69-4d8b-489e-a9fa-50dea857ce8b",
   "metadata": {},
   "source": [
    "**BAD:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558f6a6-6827-43be-83f9-00f56c526a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(text) for text in LOTS_OF_TEXTS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5458f4-2428-44b7-a54f-ec41e1a2bec9",
   "metadata": {},
   "source": [
    "**GOOD:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a4619-5efd-46d5-8da3-8e07663b1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(LOTS_OF_TEXTS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6256ab-7eb3-44a3-b8e7-673c07ab3a01",
   "metadata": {},
   "source": [
    "### Passing in context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a792d-bf92-479b-83b2-fb07e5f57f34",
   "metadata": {},
   "source": [
    "1. Setting `as_tuples=True` on `nlp.pipe` lets you pass in `(text, context)` tuples\n",
    "2. Yields `(doc, context)` tuples\n",
    "3. Useful for associating metadata with the doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf9996b0-3602-4d15-bb49-b0850b9eff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a text 15\n",
      "And another text 16\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "data = [\n",
    "    (\"This is a text\", {\"id\": 1, \"page_number\": 15}),\n",
    "    (\"And another text\", {\"id\": 2, \"page_number\": 16}),\n",
    "]\n",
    "\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    print(doc.text, context[\"page_number\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a7404-61fe-46e7-9a6e-45ffa0511ea9",
   "metadata": {},
   "source": [
    "Context can also be internalized as attributes of Docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "763c4c28-b402-45da-b4e9-1df34fe7c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "Doc.set_extension(\"id\", default=None)\n",
    "Doc.set_extension(\"page_number\", default=None)\n",
    "\n",
    "data = [\n",
    "    (\"This is a text\", {\"id\": 1, \"page_number\": 15}),\n",
    "    (\"And another text\", {\"id\": 2, \"page_number\": 16}),\n",
    "]\n",
    "\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    doc._.id = context[\"id\"]\n",
    "    doc._.page_number = context[\"page_number\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7353e-cf65-483e-95ff-453db7022c70",
   "metadata": {},
   "source": [
    "### Using only the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53af135-0a4f-4e8d-8327-f6eca47407d2",
   "metadata": {},
   "source": [
    "If you only need a tokenized `Doc` object (but not other attributes), you can use the `nlp.make_doc` method instead, which takes a text and returns a doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "974a635d-e7df-4a9d-8fad-9a20dc341d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp.make_doc(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc5612-abb9-4e30-bc60-89834135d076",
   "metadata": {},
   "source": [
    "### Disabling pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c95684d7-b29a-4e44-b18d-e1eab1f5bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/.cache/pypoetry/virtualenvs/spacy-tutorial-yidMBhfH-py3.9/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"This is a text\"\n",
    "\n",
    "# Disable tagger and parser\n",
    "with nlp.select_pipes(disable=[\"tagger\", \"parser\"]):\n",
    "    # Process the text and print the entities\n",
    "    doc = nlp(text)\n",
    "    print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08696ad-9d98-4576-adfc-4445fb55a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"exercises/en/tweets.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "# Process the texts and print the adjectives\n",
    "processed_texts = list(nlp.pipe(TEXTS))\n",
    "for doc in processed_texts:\n",
    "  print([token.text for token in doc if token.pos_ == \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afa2a3-2ceb-454f-a2d3-b7031e94c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"exercises/en/tweets.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "# Process the texts and print the entities\n",
    "docs = nlp.pipe(TEXTS)\n",
    "entities = [doc.ents for doc in docs]\n",
    "print(*entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a030f48-4041-4a03-9ec4-cb373e4a8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "people = [\"David Bowie\", \"Angela Merkel\", \"Lady Gaga\"]\n",
    "\n",
    "# Create a list of patterns for the PhraseMatcher\n",
    "patterns = nlp.pipe(people)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
